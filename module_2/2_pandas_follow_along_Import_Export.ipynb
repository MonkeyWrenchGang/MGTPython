{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiA2a0W53RhoM/UXmvZDeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonkeyWrenchGang/MGTPython/blob/main/module_2/2_pandas_follow_along_Import_Export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Importing and Exporting Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Pandas is a powerful library for data manipulation and analysis in Python, and it provides many convenient functions for importing and exporting data. In this notebook we are going to dive into importing and exporting data with pandas. \n",
        "\n"
      ],
      "metadata": {
        "id": "UQnnLgpbwkRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "\n",
        "Before we dive into the exciting world of Pandas, let's set the stage by importing the necessary libraries and configuring our environment. With all the tools at our disposal and the optimal settings in place, we'll be ready to tackle any challenge that comes our way."
      ],
      "metadata": {
        "id": "8Kq98J1nwVoz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Hm5EUepBwIM7",
        "outputId": "9b144467-d10c-4e80-e8e5-266f16ebeda1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:90% }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# -- notebook options -- \n",
        "from IPython.core.display import display, HTML\n",
        "from IPython.display import clear_output\n",
        "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# -- key libraries --\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "\n",
        "# -- need this to render charts in notebook -- \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Pandas! \n",
        "Pandas is a powerful library for data manipulation and analysis in Python, and it provides many convenient functions for importing and exporting data. Here are a few examples of some common data formats:\n",
        "\n",
        "CSV:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Importing a CSV file\n",
        "df = pd.read_csv('data.csv')\n",
        "print(df)\n",
        "\n",
        "# Exporting a CSV file\n",
        "df.to_csv('data.csv', index=False)\n",
        "\n",
        "```\n",
        "Excel:\n",
        "```python\n",
        "# Importing an Excel file\n",
        "df = pd.read_excel('data.xlsx')\n",
        "print(df)\n",
        "\n",
        "# Exporting an Excel file\n",
        "df.to_excel('data.xlsx', index=False)\n",
        "\n",
        "```\n",
        "JSON:\n",
        "```python\n",
        "# Importing a JSON file\n",
        "df = pd.read_json('data.json')\n",
        "print(df)\n",
        "\n",
        "# Exporting a JSON file\n",
        "df.to_json('data.json')\n",
        "\n",
        "```\n",
        "\n",
        "SQL:\n",
        "\n",
        "```python\n",
        "import sqlite3\n",
        "\n",
        "# Importing data from a SQL database\n",
        "con = sqlite3.connect(\"data.db\")\n",
        "df = pd.read_sql(\"SELECT * FROM data\", con)\n",
        "print(df)\n",
        "\n",
        "# Exporting data to a SQL database\n",
        "con = sqlite3.connect(\"data.db\")\n",
        "df.to_sql(\"data\", con, index=False)\n",
        "```\n",
        "\n",
        "*NOTE: Pandas provides functionality for connecting to and interacting with a variety of databases, including Oracle, DB2, Redshift, MySQL, Postgres and many others. The  sqlalchemy library is often used to  connect to remote databases via pandas.*\n",
        "\n",
        "\n",
        "In addition to these file formats, pandas also provides a convenient way to import and export data from other data sources such as databases, APIs, and others. You can use the pd.read_* and df.to_* functions for importing and exporting the data respectively."
      ],
      "metadata": {
        "id": "O1crQXMDwpMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read and Write a CSV File \n",
        "\n",
        "A CSV (Comma Separated Values) file is a plain text file format that stores tabular data in which each line of the file represents a row of the table and each field (column) within that row is separated by a comma. CSV files are simple to create and can be easily imported and exported by most spreadsheets and databases.\n",
        "\n",
        "for example:\n",
        "\n",
        "```\n",
        "Name,Age,Gender\n",
        "Alice,25,Female\n",
        "Bob,32,Male\n",
        "Charlie,28,Male\n",
        "```\n",
        "As you can see, in the CSV file the first line is usually the header containing the names of each column, and the rest of the lines contain the data, each value separated by a comma.\n",
        "\n",
        "It is also worth noting that sometimes CSV files use different delimiter characters such as semicolon (;) or tab (\\t) instead of comma. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "# Lets import CSV File! \n",
        "\n",
        "- broward_listings.csv \n",
        "- AMZN.csv\n",
        "\n",
        "Download the CSV file from Canvas to a location on your computer or on google drive. As a helper i've also included link to github hosted files. \n",
        "\n",
        "Github:\n",
        "- https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/broward_listings.csv\n",
        "- https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/AMZN.csv\n",
        "- https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/amazon.json"
      ],
      "metadata": {
        "id": "rQ7t0W44yEbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listings = pd.read_csv(\"https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/broward_listings.csv\")\n",
        "listings.head()"
      ],
      "metadata": {
        "id": "YrGh6M3ywprX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amzn = pd.read_csv(\"https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/AMZN.csv\")\n",
        "amzn.head()"
      ],
      "metadata": {
        "id": "kgvtGHmX05T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Dataframe to CSV and Excel\n",
        "\n",
        "You can use the pandas.DataFrame.to_csv() method to export a DataFrame to a CSV file. This method takes several arguments, including the file path, the separator, and the options for handling missing data.\n",
        "\n",
        "The pandas.DataFrame.to_excel() method to export a DataFrame to an Excel file. The method writes the data to an Excel sheet within a new or existing Excel file.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv('data.csv', index=False)\n",
        "df.to_csv('data.csv', sep='\\t', header=False, na_rep='NaN')\n",
        "\n",
        "\n",
        "# Write the DataFrame to an Excel file\n",
        "df.to_excel('data.xlsx', index=False)\n",
        "df.to_excel('data.xlsx', engine='openpyxl', sheet_name='Sheet1', startrow=1, startcol=1)\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Let's export our datasets! \n",
        "\n",
        "1. write AMZN to a CSV file \n",
        "2. write Listings to a Excel file \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a0r41wpX1DZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amzn.to_csv(\"amzn.csv\")"
      ],
      "metadata": {
        "id": "aGXcUuyk2Svl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listings.to_excel(\"listings.xlsx\")"
      ],
      "metadata": {
        "id": "agGbY0YT2d6-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import & Export JSON\n",
        "\n",
        "What is JSON? JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write and easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language. \n",
        "\n",
        "JSON is a collection of key-value pairs, where each key must be a string, and the value can be a string, number, boolean, null, array, or another JSON object. JSON objects are delimited with curly braces {} and are separated by commas, while keys and values are separated by colons. JSON arrays are delimited with square brackets [] and are separated by commas.\n",
        "\n",
        "Here's an example of a JSON object:\n",
        "```json\n",
        "{\n",
        "  \"name\": \"John Smith\",\n",
        "  \"age\": 35,\n",
        "  \"address\": {\n",
        "    \"street\": \"21 2nd Street\",\n",
        "    \"city\": \"New York\",\n",
        "    \"state\": \"NY\",\n",
        "    \"zip\": \"10021\"\n",
        "  },\n",
        "  \"phoneNumbers\": [\n",
        "    { \"type\": \"home\", \"number\": \"212 555-1234\" },\n",
        "    { \"type\": \"fax\", \"number\": \"646 555-4567\" }\n",
        "  ]\n",
        "}\n",
        "\n",
        "```\n",
        "Looks a lot like a python dictonary doesn't it? \n",
        "\n",
        "Anyway, lets export AMZN to JSON. \n",
        "\n",
        "```python\n",
        "# Read a JSON file\n",
        "df = pd.read_json(\"data.json\")\n",
        "\n",
        "# Exporting a JSON file\n",
        "df.to_json('data.json')\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "hi2fWEOI1amH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing JSON\n",
        "amzn_2 = pd.read_json(\"https://raw.githubusercontent.com/MonkeyWrenchGang/MGTPython/main/module_2/data/amazon.json\")\n",
        "amzn_2.head()"
      ],
      "metadata": {
        "id": "i7FFw91kstqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting a JSON file\n",
        "amzn.to_json('amazon.json')"
      ],
      "metadata": {
        "id": "2wclNjrz1avf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQLite?\n",
        "\n",
        "SQLite is a relational database management system (RDBMS) contained in a C library. It is one of the most widely-deployed SQL database engines in the world, and it is used in a wide variety of applications, including web browsers, mobile phones, operating systems, and embedded systems.\n",
        "\n",
        "SQLite is often the technology of choice for small applications, particularly those of embedded systems and devices like phones and tablets, smart appliances, or IoT gadgets as well as small and medium-sized websites, due to its small size, low-overhead, and good performance. SQLite does not require a separate server process or system to operate, and it can read and write directly to ordinary disk files.\n",
        "\n",
        "let's do some SQLite stuff! \n",
        "\n"
      ],
      "metadata": {
        "id": "g9-Z9gz51a2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "pAiZVyK31a_G"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Export Listings to SQLite\n",
        "\n",
        "You can use the pandas.DataFrame.to_sql() method to export a DataFrame to a SQLite3 database. This method takes several arguments, including the name of the table, the connection object, and the table creation mode.\n",
        "\n",
        "Here's an example of how you might export a DataFrame to an SQLite3 database:\n",
        "\n",
        "```python\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
        "\n",
        "# Connect to a database (or create one if it doesn't exist)\n",
        "con = sqlite3.connect('data.db')\n",
        "\n",
        "# Write the DataFrame to the table 'data' in the database\n",
        "df.to_sql('data', con, if_exists='replace')\n",
        "```\n",
        "Here the if_exists argument is used to specify the action to take when the table already exists in the database. The options are \"fail\", \"replace\", and \"append\".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bmMXS__M1bJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "# Connect to a database (or create one if it doesn't exist)\n",
        "con = sqlite3.connect('my_listings.db')\n",
        "\n",
        "# Write the DataFrame to the table 'data' in the database\n",
        "listings.to_sql('listings', con, if_exists='replace')\n",
        "amzn.to_sql('amzn', con, if_exists='replace')"
      ],
      "metadata": {
        "id": "4jNZ6P1V1bVx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A how about some SQL? \n",
        "\n",
        "You can use the pandas library to query a SQLite table by first connecting to the database using the sqlite3 library and then passing the query to the pandas.read_sql_query() function. \n",
        "\n",
        "Here is an example:\n",
        "```python\n",
        "import sqlite3\n",
        "# Connect to the database\n",
        "conn = sqlite3.connect(\"mydatabase.db\")\n",
        "\n",
        "# Construct the query\n",
        "query = \"SELECT * FROM mytable\"\n",
        "\n",
        "# Execute the query and store the results in a DataFrame\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We created a databasae called listings.db that contains a single table called listings, let's run a couple queries and see what happens. \n",
        "\n",
        "1. \"SELECT * FROM listings WHERE neighbourhood = 'West Park'\" \n",
        "2. \"SELECT neighbourhood, count(*) as count FROM listings GROUP BY neighbourhood ORDER BY count DESC LIMIT 10\"\n",
        "\n",
        "3. \"SELECT room_type, AVG(price) as mean_price FROM listings WHERE room_type = 'Private room' GROUP BY  room_type\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SiUDG0dt4hNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "# Connect to the database\n",
        "conn = sqlite3.connect(\"my_listings.db\")\n",
        "\n",
        "# Construct the query\n",
        "query1 = \"SELECT * FROM listings WHERE neighbourhood = 'West Park'\"\n",
        "\n",
        "# Execute the query and store the results in a DataFrame\n",
        "result1 = pd.read_sql_query(query1, conn)\n",
        "result1.head()"
      ],
      "metadata": {
        "id": "cvDVojVk5qHK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the query\n",
        "query2 = \"SELECT neighbourhood, count(*) as count FROM listings GROUP BY neighbourhood ORDER BY count DESC LIMIT 10\"\n",
        "\n",
        "# Execute the query and store the results in a DataFrame\n",
        "result2 = pd.read_sql_query(query2, conn)\n",
        "result2"
      ],
      "metadata": {
        "id": "MBsmL0Q7523S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the query\n",
        "query3 = \"SELECT room_type, AVG(price) as mean_price FROM listings GROUP BY  room_type\"\n",
        "\n",
        "# Execute the query and store the results in a DataFrame\n",
        "result3 = pd.read_sql_query(query3, conn)\n",
        "result3"
      ],
      "metadata": {
        "id": "XRjKBiiT6fpN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}